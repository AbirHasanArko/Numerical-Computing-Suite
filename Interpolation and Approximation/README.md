# Interpolation and Approximation

[![C++](https://img.shields.io/badge/Language-C++-00599C?style=for-the-badge&logo=cplusplus)](https://isocpp.org/)
[![Numerical Methods](https://img.shields.io/badge/Topic-Numerical%20Methods-FF6B6B?style=for-the-badge)](https://github.com/AbirHasanArko/Numerical-Computing-Suite)

## üìë Table of Contents

- [Introduction](#-introduction)
- [Overview of Interpolation Methods](#-overview-of-interpolation-methods)
- [Mathematical Foundation](#-mathematical-foundation)
  - [What is Interpolation?](#what-is-interpolation)
  - [What is Approximation?](#what-is-approximation)
  - [Polynomial Interpolation](#polynomial-interpolation)
  - [Fundamental Concepts](#fundamental-concepts)
- [Interpolation Methods](#-interpolation-methods)
  - [1. Newton's Forward Interpolation](#1-newtons-forward-interpolation)
  - [2. Newton's Backward Interpolation](#2-newtons-backward-interpolation)
  - [3. Newton's Divided Difference Interpolation](#3-newtons-divided-difference-interpolation)
- [Method Comparison](#-method-comparison)
- [Applications](#-applications)
- [Implementation Structure](#-implementation-structure)
- [Getting Started](#-getting-started)
- [References](#-references)
- [Author](#-author)

---

## üìñ Introduction

This section of the **Numerical Computing Suite** focuses on **interpolation and approximation** techniques for estimating unknown values between known data points.  Interpolation is a fundamental problem in numerical analysis that arises when we have discrete data points and need to estimate values at intermediate positions.

**The Core Problem**: Given a set of data points `(x‚ÇÄ, y‚ÇÄ), (x‚ÇÅ, y‚ÇÅ), ..., (x‚Çô, y‚Çô)`, find a function f(x) such that:
- f(x·µ¢) = y·µ¢ for all known points (interpolation constraint)
- f(x) provides reasonable estimates for unknown x values

Interpolation appears in countless applications: 
- **Scientific Computing**: Fitting experimental data, signal processing
- **Computer Graphics**:  Smooth curve generation, animation
- **Engineering**: Data reconstruction, sensor calibration
- **Statistics**: Missing data estimation, trend analysis
- **Finance**: Option pricing, yield curve construction

This collection provides three powerful Newton interpolation methods, each optimized for different data characteristics and use cases.

---

## üîç Overview of Interpolation Methods

This repository implements three variants of **Newton's interpolation formula**:

| Method | Data Spacing | Best For | Complexity | Key Feature |
|--------|-------------|----------|------------|-------------|
| **Newton's Forward** | Equal spacing | Near beginning | O(n¬≤) | Forward difference table |
| **Newton's Backward** | Equal spacing | Near end | O(n¬≤) | Backward difference table |
| **Newton's Divided Difference** | Any spacing | General case | O(n¬≤) | Works with non-uniform data |

---

## üìê Mathematical Foundation

### What is Interpolation?

**Interpolation** is the process of constructing new data points within the range of a discrete set of known data points. 

**Formal Definition**: Given n+1 distinct points `(x‚ÇÄ, y‚ÇÄ), (x‚ÇÅ, y‚ÇÅ), ..., (x‚Çô, y‚Çô)`, find a function f(x) from a specified class of functions such that: 

```
f(x·µ¢) = y·µ¢  for i = 0, 1, 2, ..., n
```

**Key Properties**:
- **Interpolation constraint**: The function must pass through all given data points
- **Uniqueness**: For polynomial interpolation of degree ‚â§ n, the solution is unique
- **Continuity**: The interpolating function is continuous (unlike step functions)

**Interpolation vs.  Extrapolation**:
```
Data points:   x‚ÇÄ  x‚ÇÅ  x‚ÇÇ  x‚ÇÉ  x‚ÇÑ
               |---|---|---|---|
              
Interpolation:  Estimate within [x‚ÇÄ, x‚ÇÑ]  ‚úì More reliable
Extrapolation: Estimate outside [x‚ÇÄ, x‚ÇÑ] ‚ö†Ô∏è  Less reliable, higher error
```

### What is Approximation?

**Approximation** is the broader process of finding a function that is "close to" the data points, but doesn't necessarily pass through them exactly.

**Key Differences**: 

| Aspect | Interpolation | Approximation |
|--------|--------------|---------------|
| **Exactness** | f(x·µ¢) = y·µ¢ (exact) | f(x·µ¢) ‚âà y·µ¢ (approximate) |
| **Use Case** | Exact data | Noisy data, trend fitting |
| **Flexibility** | Must pass through points | Can smooth out noise |
| **Degree** | Degree n for n+1 points | Usually lower degree |
| **Examples** | Newton, Lagrange | Least squares, splines |

**When to Use Each**:
- **Interpolation**: Data is accurate, need exact fit
- **Approximation**: Data has noise/errors, want smooth trend

### Polynomial Interpolation

**The Fundamental Theorem**:  Given n+1 distinct points, there exists a **unique polynomial of degree ‚â§ n** that passes through all points.

**General Form**: 
```
P‚Çô(x) = a‚ÇÄ + a‚ÇÅx + a‚ÇÇx¬≤ + ...  + a‚Çôx‚Åø
```

**Why Polynomials?**  
‚úÖ Easy to compute and differentiate  
‚úÖ Continuous and smooth  
‚úÖ Well-understood mathematical properties  
‚úÖ Can approximate many functions (Weierstrass Approximation Theorem)  

**Challenges**:  
‚ùå **Runge's Phenomenon**: High-degree polynomials can oscillate wildly between points  
‚ùå **Sensitivity**: Small changes in data can cause large changes in polynomial  
‚ùå **Computational Cost**: Higher degrees require more computation  

### Fundamental Concepts

#### **Finite Differences**

Finite differences measure how function values change between consecutive points.  They're the discrete analog of derivatives.

**Forward Difference Operator (Œî)**:
```
Œîy‚ÇÄ = y‚ÇÅ - y‚ÇÄ
Œî¬≤y‚ÇÄ = Œîy‚ÇÅ - Œîy‚ÇÄ = (y‚ÇÇ - y‚ÇÅ) - (y‚ÇÅ - y‚ÇÄ) = y‚ÇÇ - 2y‚ÇÅ + y‚ÇÄ
Œî‚Åøy·µ¢ = Œî‚Åø‚Åª¬πy·µ¢‚Çä‚ÇÅ - Œî‚Åø‚Åª¬πy·µ¢
```

**Backward Difference Operator (‚àá)**:
```
‚àáy‚Çô = y‚Çô - y‚Çô‚Çã‚ÇÅ
‚àá¬≤y‚Çô = ‚àáy‚Çô - ‚àáy‚Çô‚Çã‚ÇÅ = (y‚Çô - y‚Çô‚Çã‚ÇÅ) - (y‚Çô‚Çã‚ÇÅ - y‚Çô‚Çã‚ÇÇ) = y‚Çô - 2y‚Çô‚Çã‚ÇÅ + y‚Çô‚Çã‚ÇÇ
‚àá‚Åøy·µ¢ = ‚àá‚Åø‚Åª¬πy·µ¢ - ‚àá‚Åø‚Åª¬πy·µ¢‚Çã‚ÇÅ
```

**Divided Difference** (for non-uniform spacing):
```
f[x‚ÇÄ, x‚ÇÅ] = (f(x‚ÇÅ) - f(x‚ÇÄ)) / (x‚ÇÅ - x‚ÇÄ)
f[x‚ÇÄ, x‚ÇÅ, x‚ÇÇ] = (f[x‚ÇÅ, x‚ÇÇ] - f[x‚ÇÄ, x‚ÇÅ]) / (x‚ÇÇ - x‚ÇÄ)
```

**Visual Example**: Forward Difference Table for y = x¬≤

```
x    y    Œîy   Œî¬≤y   Œî¬≥y
0    0    
           1
1    1          2
           3         0
2    4          2
           5         0
3    9          2
           7
4    16
```

#### **Difference Tables**

A **difference table** organizes successive differences in a triangular structure, making patterns visible and computation efficient.

**Properties**:
- For a polynomial of degree n, the nth differences are constant
- Higher-order differences become zero
- Helps detect errors in data (irregular patterns indicate problems)

#### **Interpolating Polynomial Uniqueness**

**Theorem**: Given n+1 distinct points, the interpolating polynomial of degree ‚â§ n is unique.

**Proof Sketch**:
- Suppose P(x) and Q(x) both interpolate the data
- Then R(x) = P(x) - Q(x) has n+1 roots (at all data points)
- But R(x) has degree ‚â§ n
- A polynomial of degree n can have at most n roots (unless it's zero)
- Therefore R(x) ‚â° 0, so P(x) = Q(x)

**Implication**: All interpolation methods (Newton, Lagrange, etc.) produce the same polynomial, just in different forms! 

#### **Error Analysis**

The **interpolation error** measures how far the interpolating polynomial is from the true function.

**Error Bound** (for polynomial interpolation):
```
|f(x) - P‚Çô(x)| ‚â§ (M‚Çô‚Çä‚ÇÅ/(n+1)!) √ó |(x-x‚ÇÄ)(x-x‚ÇÅ)...(x-x‚Çô)|
```

Where M‚Çô‚Çä‚ÇÅ = max|f‚ÅΩ‚Åø‚Å∫¬π‚Åæ(x)| over the interval. 

**Key Insights**:
- Error depends on f‚ÅΩ‚Åø‚Å∫¬π‚Åæ (smoothness of function)
- Error is smallest near the middle of data points
- Error grows near the boundaries (especially for high-degree polynomials)
- Product term |(x-x‚ÇÄ)(x-x‚ÇÅ)...(x-x‚Çô)| is zero at data points (as expected)

---

## üõ†Ô∏è Interpolation Methods

## 1. Newton's Forward Interpolation

[![View Implementation](https://img.shields.io/badge/üìÇ-View%20Implementation-blue?style=for-the-badge)](./Newton's%20Forward%20Interpolation/)

### Theory

**Newton's Forward Interpolation** (also called **Newton's Forward Difference Formula**) is a polynomial interpolation method specifically designed for **equally spaced data points**. It's most accurate when interpolating near the **beginning** of the dataset.

### Historical Context

Named after Sir Isaac Newton (1642-1727), this method appeared in his work on finite differences in the 1670s. Newton recognized that equally spaced data allows for simpler formulas using difference operators, making hand calculations more practical before the computer age.

### Mathematical Foundation

**Assumptions**:
1. Data points are **equally spaced**:  x·µ¢‚Çä‚ÇÅ - x·µ¢ = h (constant step size)
2. Interpolation point x is **near the beginning** of the data range
3. Function is reasonably smooth

**The Formula**: 

Given data points at x‚ÇÄ, x‚ÇÅ, x‚ÇÇ, ..., x‚Çô with equal spacing h, the interpolating polynomial is:

```
P‚Çô(x) = y‚ÇÄ + uŒîy‚ÇÄ + [u(u-1)/2! ]Œî¬≤y‚ÇÄ + [u(u-1)(u-2)/3!]Œî¬≥y‚ÇÄ + ... 
```

Where:
- **u = (x - x‚ÇÄ) / h** (normalized position)
- **Œî ≤y‚ÇÄ** = jth forward difference at x‚ÇÄ
- The formula uses differences at the **first point** (x‚ÇÄ)

**General Term**:
```
Term_k = [u(u-1)(u-2)...(u-k+1) / k!] √ó Œî·µèy‚ÇÄ
```

#### Why "Forward" Difference?

The method is called "forward" because: 
- It uses the forward difference operator Œî
- Differences are computed moving forward from x‚ÇÄ
- Most accurate for interpolation near the start (where u is small)

**Forward Difference Table Structure**:

```
x     y       Œîy      Œî¬≤y     Œî¬≥y     Œî‚Å¥y
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
x‚ÇÄ    y‚ÇÄ      
             Œîy‚ÇÄ
x‚ÇÅ    y‚ÇÅ             Œî¬≤y‚ÇÄ
             Œîy‚ÇÅ             Œî¬≥y‚ÇÄ
x‚ÇÇ    y‚ÇÇ             Œî¬≤y‚ÇÅ            Œî‚Å¥y‚ÇÄ
             Œîy‚ÇÇ             Œî¬≥y‚ÇÅ
x‚ÇÉ    y‚ÇÉ             Œî¬≤y‚ÇÇ
             Œîy‚ÇÉ
x‚ÇÑ    y‚ÇÑ
```

**Key Observation**: All differences needed are in the **top row** or **diagonal from top**. 

### Detailed Algorithm

##### **Step 1: Validate Equal Spacing**

```
h = x‚ÇÅ - x‚ÇÄ
For i = 1 to n-1:
    If |x·µ¢‚Çä‚ÇÅ - x·µ¢ - h| > Œµ: 
        Error:  "Data points must be equally spaced"
```

##### **Step 2: Build Forward Difference Table**

```
Initialize table[n][n]
table[i][0] = y·µ¢ for all i  (first column = y values)

For j = 1 to n-1:           (difference order)
    For i = 0 to n-j-1:     (starting position)
        table[i][j] = table[i+1][j-1] - table[i][j-1]
```

**Example**: Data points (0, 1), (1, 2), (2, 5), (3, 10)

```
Initial: 
i   x   y=table[i][0]
0   0   1
1   1   2
2   2   5
3   3   10

After j=1 (first differences):
table[0][1] = table[1][0] - table[0][0] = 2 - 1 = 1
table[1][1] = table[2][0] - table[1][0] = 5 - 2 = 3
table[2][1] = table[3][0] - table[2][0] = 10 - 5 = 5

After j=2 (second differences):
table[0][2] = table[1][1] - table[0][1] = 3 - 1 = 2
table[1][2] = table[2][1] - table[1][1] = 5 - 3 = 2

After j=3 (third differences):
table[0][3] = table[1][2] - table[0][2] = 2 - 2 = 0

Final Table:
x   y    Œîy   Œî¬≤y  Œî¬≥y
0   1    1    2    0
1   2    3    2
2   5    5
3   10
```

##### **Step 3: Interpolation**

For a given interpolation point x:

```
u = (x - x‚ÇÄ) / h

result = table[0][0]  (= y‚ÇÄ)
u_term = 1. 0
factorial = 1.0

For j = 1 to n-1:
    u_term = u_term √ó (u - (j-1))
    factorial = factorial √ó j
    term = (u_term / factorial) √ó table[0][j]
    result = result + term
    
    If |term| < Œµ:  // Early termination if contribution negligible
        break

Return result
```

#### Detailed Example Walkthrough

**Given**:  Approximate f(1.5) using the data: 

```
x:  1.0   1.5   2.0   2.5   3.0
y:  0.0   0.41  0.69  0.92  1.10
```

**Step 1**: Verify equal spacing
```
h = 1.5 - 1.0 = 0.5 ‚úì
All intervals = 0.5 ‚úì
```

**Step 2**: Build forward difference table

```
x    y      Œîy      Œî¬≤y      Œî¬≥y      Œî‚Å¥y
1.0  0.00   0.41    -0.13    0.02     -0.01
1.5  0.41   0.28    -0.11    0.01
2.0  0.69   0.23    -0.10
2.5  0.92   0.18
3.0  1.10
```

Calculations:
- Œîy‚ÇÄ = 0.41 - 0.00 = 0.41
- Œî¬≤y‚ÇÄ = 0.28 - 0.41 = -0.13
- Œî¬≥y‚ÇÄ = -0.11 - (-0.13) = 0.02
- Œî‚Å¥y‚ÇÄ = 0.01 - 0.02 = -0.01

**Step 3**: Interpolate at x = 1.5
```
u = (1.5 - 1.0) / 0.5 = 1.0

P(1.5) = y‚ÇÄ + uŒîy‚ÇÄ + [u(u-1)/2!]Œî¬≤y‚ÇÄ + [u(u-1)(u-2)/3!]Œî¬≥y‚ÇÄ + ... 

Term 0: y‚ÇÄ = 0.00
Term 1: 1.0 √ó 0.41 = 0.41
Term 2: [1.0(1.0-1)/2] √ó (-0.13) = 0.00
Term 3: [1.0(1.0-1)(1.0-2)/6] √ó 0.02 = 0.00
Term 4: [1.0(1.0-1)(1.0-2)(1.0-3)/24] √ó (-0.01) = 0.00

Result: P(1.5) = 0.00 + 0.41 = 0.41 ‚úì
```

(This matches the table value because 1.5 is an actual data point!)

**Step 4**: Interpolate at x = 1.25 (between data points)
```
u = (1.25 - 1.0) / 0.5 = 0.5

Term 0: 0.00
Term 1: 0.5 √ó 0.41 = 0.205
Term 2: [0.5(0.5-1)/2] √ó (-0.13) = [0.5√ó(-0.5)/2] √ó (-0.13) = 0.01625
Term 3: [0.5√ó(-0.5)√ó(-1. 5)/6] √ó 0.02 = 0.00125
Term 4: [0.5√ó(-0.5)√ó(-1.5)√ó(-2.5)/24] √ó (-0.01) ‚âà -0.00039

Result: P(1.25) ‚âà 0.00 + 0.205 + 0.016 + 0.001 ‚âà 0.222
```

### When to Use Forward Interpolation

**Optimal Scenarios**:  
‚úÖ Equally spaced data points  
‚úÖ Interpolation near the **beginning** of the dataset (u ‚âà 0 to 1)  
‚úÖ Tabulated data (like mathematical tables)  
‚úÖ Sequential data processing  

**Performance Characteristics**:
- **Most accurate**:  When 0 ‚â§ u ‚â§ 1 (first interval)
- **Good accuracy**: When 0 ‚â§ u ‚â§ 2 (first two intervals)
- **Degrading accuracy**: When u > 2 (far from start)

**Avoid When**:  
‚ùå Data points are not equally spaced (use divided differences)  
‚ùå Interpolating near the end of dataset (use backward interpolation)  
‚ùå High-degree polynomial needed (risk of Runge's phenomenon)  

### Complexity Analysis

**Time Complexity**: 

1. **Building Difference Table** (one-time):
   - Outer loop: j = 1 to n-1
   - Inner loop: i = 0 to n-j-1
   - Total operations:  Œ£‚±º‚Çå‚ÇÅ‚Åø‚Åª¬π(n-j) = n(n-1)/2
   - **Complexity**: O(n¬≤)

2. **Single Interpolation** (using pre-built table):
   - Loop: k = 1 to n-1
   - Each iteration: O(1) operations
   - **Complexity**:  O(n)

3. **Total for k Interpolations**:
   - Build once: O(n¬≤)
   - k interpolations: O(kn)
   - **Overall**: O(n¬≤ + kn)

**Space Complexity**:
- Difference table: n√ón matrix (though only upper triangle used)
- **Space**: O(n¬≤)
- Can be optimized to O(n) if only storing diagonal

**Operation Counts** (for single interpolation with n points):
- **Multiplications**: ~n¬≤ (table) + ~n¬≤ (interpolation) ‚âà 2n¬≤
- **Additions/Subtractions**: ~n¬≤/2 (table) + ~n (interpolation)
- **Divisions**: ~n (computing u terms and factorials)

### Numerical Considerations

**Sources of Error**: 

1. **Truncation Error**:
   - From stopping at finite degree
   - Magnitude:  O(h‚Åø‚Å∫¬π) where h is step size
   - Solution: Use more data points or smaller h

2. **Round-off Error**:
   - From finite precision arithmetic
   - Accumulates in difference table
   - Solution: Use double precision, check for constant high-order differences

3. **Runge's Phenomenon**:
   - High-degree polynomials oscillate
   - Especially problematic with many points
   - Solution:  Limit polynomial degree or use piecewise interpolation

**Stability Tips**:  
‚úÖ Verify equal spacing with tolerance check  
‚úÖ Check for constant high-order differences (indicates polynomial degree)  
‚úÖ Use double precision for all calculations  
‚úÖ Validate interpolation point is within reasonable range  
‚úÖ Limit polynomial degree to avoid oscillations  

#### Advantages & Limitations

**Advantages**:  
‚úÖ **Simple and intuitive** formula  
‚úÖ **Efficient** for equally spaced data  
‚úÖ **Reusable table** for multiple interpolations  
‚úÖ **Pattern recognition** - constant differences reveal polynomial degree  
‚úÖ **Natural fit** for tabulated data  
‚úÖ **Easy error estimation** from high-order terms  
‚úÖ **Historical tables** already in this format  

**Limitations**:  
‚ùå **Requires equal spacing** - strict constraint  
‚ùå **Best near start** - accuracy degrades away from x‚ÇÄ  
‚ùå **High-degree issues** - oscillations with many points  
‚ùå **Memory intensive** - O(n¬≤) storage  
‚ùå **Not general-purpose** - specific use case  

---

## 2. Newton's Backward Interpolation

[![View Implementation](https://img.shields.io/badge/üìÇ-View%20Implementation-green?style=for-the-badge)](./Newton's%20Backward%20Interpolation/)

### Theory

**Newton's Backward Interpolation** (also called **Newton's Backward Difference Formula**) is the mirror image of forward interpolation. It's specifically designed for **equally spaced data points** and is most accurate when interpolating near the **end** of the dataset.

### Historical Context

Developed alongside the forward formula, backward interpolation became essential for astronomical and navigational tables where extrapolation beyond the last known value was common.  By working backward from the end, it provides better accuracy for such calculations.

### Mathematical Foundation

**Assumptions**:
1. Data points are **equally spaced**: x·µ¢‚Çä‚ÇÅ - x·µ¢ = h (constant step size)
2. Interpolation point x is **near the end** of the data range
3. Function is reasonably smooth

**The Formula**:

Given data points at x‚ÇÄ, x‚ÇÅ, x‚ÇÇ, ..., x‚Çô with equal spacing h, the interpolating polynomial is: 

```
P‚Çô(x) = y‚Çô + u‚àáy‚Çô + [u(u+1)/2!]‚àá¬≤y‚Çô + [u(u+1)(u+2)/3!]‚àá¬≥y‚Çô + ...
```

Where:
- **u = (x - x‚Çô) / h** (normalized position from the end)
- **‚àá ≤y‚Çô** = jth backward difference at x‚Çô (last point)
- The formula uses differences at the **last point** (x‚Çô)

**General Term**:
```
Term_k = [u(u+1)(u+2)...(u+k-1) / k!] √ó ‚àá·µèy‚Çô
```

**Key Difference from Forward**:
- Forward uses:  u(u-1)(u-2)... and Œî ≤y‚ÇÄ (from start)
- Backward uses: u(u+1)(u+2)... and ‚àá ≤y‚Çô (from end)

#### Why "Backward" Difference? 

The method is called "backward" because:
- It uses the backward difference operator ‚àá
- Differences are computed moving backward from x‚Çô
- Most accurate for interpolation near the end (where u is small in magnitude)

**Backward Difference Table Structure**:

```
x     y       ‚àáy      ‚àá¬≤y     ‚àá¬≥y     ‚àá‚Å¥y
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
x‚ÇÄ    y‚ÇÄ      
              ‚àáy‚ÇÅ
x‚ÇÅ    y‚ÇÅ             ‚àá¬≤y‚ÇÇ
              ‚àáy‚ÇÇ             ‚àá¬≥y‚ÇÉ
x‚ÇÇ    y‚ÇÇ             ‚àá¬≤y‚ÇÉ             ‚àá‚Å¥y‚ÇÑ
              ‚àáy‚ÇÉ             ‚àá¬≥y‚ÇÑ
x‚ÇÉ    y‚ÇÉ             ‚àá¬≤y‚ÇÑ
              ‚àáy‚ÇÑ
x‚ÇÑ    y‚ÇÑ    ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Bottom row
```

**Key Observation**: All differences needed are in the **bottom row** or **diagonal to bottom**.

### Detailed Algorithm

##### **Step 1: Validate Equal Spacing**

```
h = x‚ÇÅ - x‚ÇÄ
For i = 1 to n-1:
    If |x·µ¢‚Çä‚ÇÅ - x·µ¢ - h| > Œµ: 
        Error: "Data points must be equally spaced"
```

##### **Step 2: Build Backward Difference Table**

```
Initialize table[n][n]
table[i][0] = y·µ¢ for all i  (first column = y values)

For j = 1 to n-1:           (difference order)
    For i = n-1 down to j:  (starting from bottom)
        table[i][j] = table[i][j-1] - table[i-1][j-1]
```

**Key Difference from Forward**:  The inner loop goes **bottom-to-top** (i = n-1 down to j).

**Example**: Data points (0, 1), (1, 2), (2, 5), (3, 10)

```
Initial:
i   x   y=table[i][0]
0   0   1
1   1   2
2   2   5
3   3   10

After j=1 (first backward differences):
table[3][1] = table[3][0] - table[2][0] = 10 - 5 = 5
table[2][1] = table[2][0] - table[1][0] = 5 - 2 = 3
table[1][1] = table[1][0] - table[0][0] = 2 - 1 = 1

After j=2 (second backward differences):
table[3][2] = table[3][1] - table[2][1] = 5 - 3 = 2
table[2][2] = table[2][1] - table[1][1] = 3 - 1 = 2

After j=3 (third backward differences):
table[3][3] = table[3][2] - table[2][2] = 2 - 2 = 0

Final Backward Difference Table:
x   y    ‚àáy   ‚àá¬≤y  ‚àá¬≥y
0   1    
1   2    1
2   5    3    2
3   10   5    2    0  ‚Üê bottom row contains all needed differences
```

##### **Step 3: Interpolation**

For a given interpolation point x near the end:

```
u = (x - x‚Çô) / h  // Note: typically negative for interpolation

result = table[n-1][0]  (= y‚Çô, last y value)
u_term = 1.0
factorial = 1.0

For j = 1 to n-1:
    u_term = u_term √ó (u + (j-1))  // Note: u+0, u+1, u+2, ...
    factorial = factorial √ó j
    term = (u_term / factorial) √ó table[n-1][j]  // Use bottom row
    result = result + term
    
    If |term| < Œµ: 
        break

Return result
```

**Critical Detail**: u_term multiplies by (u + j-1), not (u - j+1) like forward! 

#### Detailed Example Walkthrough

**Given**: Approximate f(2.75) using the data:

```
x:  1.0   1.5   2.0   2.5   3.0
y:  0.0   0.41  0.69  0.92  1.10
```

**Step 1**: Verify equal spacing
```
h = 0.5 ‚úì
```

**Step 2**: Build backward difference table

```
x    y      ‚àáy      ‚àá¬≤y      ‚àá¬≥y      ‚àá‚Å¥y
1.0  0.00   
1.5  0.41   0.41   
2.0  0.69   0.28    -0.13
2.5  0.92   0.23    -0.05    0.08
3.0  1.10   0.18    -0.05    0.00     -0.08  ‚Üê bottom row
```

Backward differences (calculated bottom-up):
- ‚àáy‚ÇÑ = y‚ÇÑ - y‚ÇÉ = 1.10 - 0.92 = 0.18
- ‚àá¬≤y‚ÇÑ = ‚àáy‚ÇÑ - ‚àáy‚ÇÉ = 0.18 - 0.23 = -0.05
- ‚àá¬≥y‚ÇÑ = ‚àá¬≤y‚ÇÑ - ‚àá¬≤y‚ÇÉ = -0.05 - (-0.05) = 0.00
- ‚àá‚Å¥y‚ÇÑ = ‚àá¬≥y‚ÇÑ - ‚àá¬≥y‚ÇÉ = 0.00 - 0.08 = -0.08

**Step 3**: Interpolate at x = 2.75
```
n = 4 (index of last point is 4)
x‚Çô = 3.0
u = (2.75 - 3.0) / 0.5 = -0.5

P(2.75) = y‚Çô + u‚àáy‚Çô + [u(u+1)/2!]‚àá¬≤y‚Çô + [u(u+1)(u+2)/3!]‚àá¬≥y‚Çô + ...

Term 0: y‚ÇÑ = 1.10
Term 1: (-0.5) √ó 0.18 = -0.09
Term 2: [(-0.5)(0.5)/2] √ó (-0.05) = [-0.25/2] √ó (-0.05) = 0.00625
Term 3: [(-0.5)(0.5)(1.5)/6] √ó 0.00 = 0.00
Term 4: [(-0.5)(0.5)(1.5)(2.5)/24] √ó (-0.08) ‚âà 0.0039

Result: P(2.75) ‚âà 1.10 - 0.09 + 0.006 + 0.004 ‚âà 1.020
```

**Verification**: This is between y‚ÇÉ = 0.92 and y‚ÇÑ = 1.10, which makes sense!  ‚úì

### Forward vs Backward:  Direct Comparison

**Same Polynomial, Different Representation**: 

Both methods produce the **same interpolating polynomial**, just expressed differently! 

| Aspect | Forward | Backward |
|--------|---------|----------|
| **Reference Point** | First point (x‚ÇÄ) | Last point (x‚Çô) |
| **Parameter u** | (x - x‚ÇÄ) / h | (x - x‚Çô) / h |
| **Typical u Range** | 0 to n | -n to 0 |
| **Difference Operator** | Œî (forward) | ‚àá (backward) |
| **Table Row Used** | Top row | Bottom row |
| **Terms** | u(u-1)(u-2)... | u(u+1)(u+2)... |
| **Best Accuracy** | Near start (small u) | Near end (u ‚âà 0) |
| **Use Case** | Interpolation at beginning | Interpolation at end |

**Example**:  For the same data and interpolation point in the middle, both give the same result (within numerical precision).

### When to Use Backward Interpolation

**Optimal Scenarios**:  
‚úÖ Equally spaced data points  
‚úÖ Interpolation near the **end** of the dataset  
‚úÖ **Extrapolation** slightly beyond last point (with caution)  
‚úÖ Time series where most recent data is most relevant  
‚úÖ Sequential processing from end to start  

**Performance Characteristics**:
- **Most accurate**: When -1 ‚â§ u ‚â§ 0 (last interval)
- **Good accuracy**:  When -2 ‚â§ u ‚â§ 0 (last two intervals)
- **Degrading accuracy**: When u < -2 (far from end)

**Real-World Example**:
Stock price prediction:  If you have daily prices and want to estimate tomorrow's price (extrapolation beyond last point), backward interpolation is more appropriate than forward.

### Complexity Analysis

**Time Complexity**: 
- **Building Table**: O(n¬≤) - same as forward
- **Single Interpolation**: O(n) - same as forward
- **k Interpolations**: O(n¬≤ + kn)

**Space Complexity**:
- O(n¬≤) for full table
- Can optimize to O(n) storing only bottom diagonal

**Operation Counts**:  Identical to forward interpolation

#### Numerical Considerations

**Error Sources**:  Same as forward interpolation
- Truncation error from finite degree
- Round-off error in arithmetic
- Runge's phenomenon for high degrees

**Extrapolation Warning**:
```
‚ö†Ô∏è  Extrapolating beyond x‚Çô (u > 0) can be very inaccurate! 
    Use with extreme caution and check reasonableness. 
```

**Why Extrapolation is Risky**:
- No data to constrain polynomial beyond last point
- High-degree terms dominate
- Small errors in data cause large errors in extrapolation

#### Advantages & Limitations

**Advantages**:  
‚úÖ **Mirror of forward** - same theoretical properties  
‚úÖ **Better for end points** - accuracy where forward is weak  
‚úÖ **Complements forward** - choose based on interpolation location  
‚úÖ **Same efficiency** - O(n¬≤) table, O(n) interpolation  
‚úÖ **Historical importance** - essential for navigation tables  

**Limitations**:  
‚ùå **Same restrictions as forward** - needs equal spacing  
‚ùå **Not general-purpose** - specific to end-region interpolation  
‚ùå **Extrapolation dangers** - easily misused  
‚ùå **Memory intensive** - O(n¬≤) storage  

---

## 3. Newton's Divided Difference Interpolation

[![View Implementation](https://img.shields.io/badge/üìÇ-View%20Implementation-orange?style=for-the-badge)](./Newton's%20Divided%20Difference%20Interpolation/)

### Theory

**Newton's Divided Difference Interpolation** is the most **general form** of Newton's interpolation method. Unlike forward and backward interpolation which require equally spaced data, this method works with **arbitrarily spaced data points**, making it the most versatile and widely applicable interpolation technique.

### Historical Context

This is Newton's original formulation of polynomial interpolation from his work in the 1670s-1680s. The method predates the specialized forward/backward formulas, which were later simplified for the common case of equal spacing.  The divided difference approach represents the foundational theory underlying all Newton interpolation methods.

### Mathematical Foundation

**Key Advantage**: **No assumption about data spacing** - works with any distinct x-values! 

**Assumptions**:
1. Data points have **distinct x-values** (no duplicates)
2. Points can be in **any order** (though sorted is conventional)
3. Spacing can be **completely arbitrary**
4. Function is reasonably smooth

**The Formula**:

Given data points (x‚ÇÄ, y‚ÇÄ), (x‚ÇÅ, y‚ÇÅ), ..., (x‚Çô, y‚Çô), the interpolating polynomial is:

```
P‚Çô(x) = f[x‚ÇÄ] + f[x‚ÇÄ,x‚ÇÅ](x-x‚ÇÄ) + f[x‚ÇÄ,x‚ÇÅ,x‚ÇÇ](x-x‚ÇÄ)(x-x‚ÇÅ) + ... 
        + f[x‚ÇÄ,... ,x‚Çô](x-x‚ÇÄ)(x-x‚ÇÅ).. .(x-x‚Çô‚Çã‚ÇÅ)
```

Where **f[x‚ÇÄ, x‚ÇÅ, ..., x‚Çñ]** is the **kth divided difference**. 

**Compact Form**:
```
P‚Çô(x) = Œ£‚Çñ‚Çå‚ÇÄ‚Åø f[x‚ÇÄ,... ,x‚Çñ] ‚àè‚±º‚Çå‚ÇÄ·µè‚Åª¬π(x - x‚±º)
```

### Divided Differences:  The Core Concept

**Divided differences** are a generalization of derivatives and differences that work for non-uniform spacing. 

**Recursive Definition**: 

**Order 0** (zeroth divided difference):
```
f[x·µ¢] = f(x·µ¢) = y·µ¢
```
Just the function value! 

**Order 1** (first divided difference):
```
f[x·µ¢, x·µ¢‚Çä‚ÇÅ] = (f[x·µ¢‚Çä‚ÇÅ] - f[x·µ¢]) / (x·µ¢‚Çä‚ÇÅ - x·µ¢)
            = (y·µ¢‚Çä‚ÇÅ - y·µ¢) / (x·µ¢‚Çä‚ÇÅ - x·µ¢)
```
This is the **slope** between two points!

**Order 2** (second divided difference):
```
f[x·µ¢, x·µ¢‚Çä‚ÇÅ, x·µ¢‚Çä‚ÇÇ] = (f[x·µ¢‚Çä‚ÇÅ,x·µ¢‚Çä‚ÇÇ] - f[x·µ¢,x·µ¢‚Çä‚ÇÅ]) / (x·µ¢‚Çä‚ÇÇ - x·µ¢)
```

**General Order k**:
```
f[x·µ¢, x·µ¢‚Çä‚ÇÅ, .. ., x·µ¢‚Çä‚Çñ] = (f[x·µ¢‚Çä‚ÇÅ,... ,x·µ¢‚Çä‚Çñ] - f[x·µ¢,... ,x·µ¢‚Çä‚Çñ‚Çã‚ÇÅ]) / (x·µ¢‚Çä‚Çñ - x·µ¢)
```

**Key Properties**:
1. **Symmetric**: f[x‚ÇÄ, x‚ÇÅ, x‚ÇÇ] = f[x‚ÇÅ, x‚ÇÄ, x‚ÇÇ] = f[x‚ÇÇ, x‚ÇÅ, x‚ÇÄ] (order doesn't matter!)
2. **Connection to derivatives**: If spacing ‚Üí 0, f[x,x+h] ‚Üí f'(x)
3. **Polynomial detection**: For polynomial of degree n, (n+1)th divided differences are constant
4. **Reduces to forward differences**:  When h is constant, f[x‚ÇÄ, x‚ÇÅ] = Œîy‚ÇÄ/h

#### Why "Divided" Difference?

Called "divided" because we **divide by the x-interval** (x·µ¢‚Çä‚Çñ - x·µ¢), making it a **rate of change** that generalizes to non-uniform spacing.

**Intuition**:
- First divided difference: average rate of change (slope)
- Second divided difference:  rate of change of rate of change (curvature)
- Higher orders:  increasingly subtle shape information

#### Divided Difference Table Structure

Unlike forward/backward tables, the divided difference table has a different structure:

```
x       f[x·µ¢]    f[x·µ¢,x·µ¢‚Çä‚ÇÅ]   f[x·µ¢,x·µ¢‚Çä‚ÇÅ,x·µ¢‚Çä‚ÇÇ]   f[x‚ÇÄ... x‚ÇÉ]   f[x‚ÇÄ...x‚ÇÑ]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
x‚ÇÄ      y‚ÇÄ       f[x‚ÇÄ,x‚ÇÅ]      f[x‚ÇÄ,x‚ÇÅ,x‚ÇÇ]       f[x‚ÇÄ... x‚ÇÉ]   f[x‚ÇÄ...x‚ÇÑ]
x‚ÇÅ      y‚ÇÅ       f[x‚ÇÅ,x‚ÇÇ]      f[x‚ÇÅ,x‚ÇÇ,x‚ÇÉ]       f[x‚ÇÅ...x‚ÇÑ]
x‚ÇÇ      y‚ÇÇ       f[x‚ÇÇ,x‚ÇÉ]      f[x‚ÇÇ,x‚ÇÉ,x‚ÇÑ]
x‚ÇÉ      y‚ÇÉ       f[x‚ÇÉ,x‚ÇÑ]
x‚ÇÑ      y‚ÇÑ
```

**Key Observation**: The **top row** contains all coefficients needed for the interpolating polynomial! 

### Detailed Algorithm

##### **Step 1: Validate Input**

```
For i = 0 to n-1:
    For j = i+1 to n:
        If |x·µ¢ - x‚±º| < Œµ:
            Error:  "Duplicate x-values detected"
```

**Why This Matters**:  Duplicate x-values cause **division by zero** in divided difference formula!

##### **Step 2: Build Divided Difference Table**

```
Initialize table[n][n]

// Column 0: function values
For i = 0 to n-1:
    table[i][0] = y·µ¢

// Build subsequent columns
For j = 1 to n-1:              // Column (difference order)
    For i = 0 to n-j-1:        // Row (starting position)
        numerator = table[i+1][j-1] - table[i][j-1]
        denominator = x[i+j] - x[i]
        table[i][j] = numerator / denominator
```

**Example**: Data points (1, 1), (2, 8), (4, 64), (5, 125)

```
Step-by-step construction: 

Column 0 (f[x·µ¢]):
table[0][0] = 1
table[1][0] = 8
table[2][0] = 64
table[3][0] = 125

Column 1 (f[x·µ¢, x·µ¢‚Çä‚ÇÅ]):
table[0][1] = (8 - 1) / (2 - 1) = 7
table[1][1] = (64 - 8) / (4 - 2) = 28
table[2][1] = (125 - 64) / (5 - 4) = 61

Column 2 (f[x·µ¢, x·µ¢‚Çä‚ÇÅ, x·µ¢‚Çä‚ÇÇ]):
table[0][2] = (28 - 7) / (4 - 1) = 7
table[1][2] = (61 - 28) / (5 - 2) = 11

Column 3 (f[x‚ÇÄ, x‚ÇÅ, x‚ÇÇ, x‚ÇÉ]):
table[0][3] = (11 - 7) / (5 - 1) = 1

Final Table:
x    f[x·µ¢]   f[.,.]   f[. ,. ,.] f[.,.,.,. ] 
1    1       7        7        1
2    8       28       11
4    64      61
5    125
```

**Pattern Recognition**:  These are coefficients of x¬≥ (since constant 4th divided difference doesn't exist here with 4 points).

##### **Step 3: Interpolation Using Nested Multiplication (Horner's Method)**

For a given interpolation point x, evaluate P‚Çô(x) efficiently:

```
// Horner's method (most efficient)
result = table[n-1][n-1]  // Start with highest-order term
For i = n-2 down to 0:
    result = result √ó (x - x[i]) + table[i][i]

Return result
```

**Alternative (Direct Evaluation)**:
```
result = table[0][0]
term = 1.0

For k = 1 to n-1:
    term = term √ó (x - x[k-1])
    result = result + table[0][k] √ó term

Return result
```

Both methods give the same result; Horner's is slightly more efficient. 

#### Detailed Example Walkthrough

**Given**: Approximate f(3) using data:  (0, 1), (0.7, 2.014), (1.3, 3.669), (2.0, 7.389)

These represent f(x) = e^x evaluated at unequally spaced points.

**Step 1**:  Validate - no duplicate x-values ‚úì

**Step 2**:  Build divided difference table

```
x     f[x·µ¢]    f[x·µ¢,x·µ¢‚Çä‚ÇÅ]   f[x·µ¢,x·µ¢‚Çä‚ÇÅ,x·µ¢‚Çä‚ÇÇ]   f[x‚ÇÄ...x‚ÇÉ]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
0. 0   1.000    1.449        1.008              0.479
0.7   2.014    2.758        1.966
1.3   3.669    5.314
2.0   7.389
```

Calculations:
```
f[x‚ÇÄ,x‚ÇÅ] = (2.014 - 1.000) / (0.7 - 0.0) = 1.014 / 0.7 = 1.449
f[x‚ÇÅ,x‚ÇÇ] = (3.669 - 2.014) / (1.3 - 0.7) = 1.655 / 0.6 = 2.758
f[x‚ÇÇ,x‚ÇÉ] = (7.389 - 3.669) / (2.0 - 1.3) = 3.720 / 0.7 = 5.314

f[x‚ÇÄ,x‚ÇÅ,x‚ÇÇ] = (2.758 - 1.449) / (1.3 - 0.0) = 1.309 / 1.3 = 1.008
f[x‚ÇÅ,x‚ÇÇ,x‚ÇÉ] = (5.314 - 2.758) / (2.0 - 0.7) = 2.556 / 1.3 = 1.966

f[x‚ÇÄ,x‚ÇÅ,x‚ÇÇ,x‚ÇÉ] = (1.966 - 1.008) / (2.0 - 0.0) = 0.958 / 2.0 = 0.479
```

**Step 3**: Interpolate at x = 3

Using direct evaluation:
```
P‚ÇÉ(3) = f[x‚ÇÄ] 
      + f[x‚ÇÄ,x‚ÇÅ](3-x‚ÇÄ) 
      + f[x‚ÇÄ,x‚ÇÅ,x‚ÇÇ](3-x‚ÇÄ)(3-x‚ÇÅ) 
      + f[x‚ÇÄ,x‚ÇÅ,x‚ÇÇ,x‚ÇÉ](3-x‚ÇÄ)(3-x‚ÇÅ)(3-x‚ÇÇ)

     = 1.000 
     + 1.449 √ó (3 - 0) 
     + 1.008 √ó (3 - 0) √ó (3 - 0.7) 
     + 0.479 √ó (3 - 0) √ó (3 - 0.7) √ó (3 - 1.3)

     = 1.000 
     + 1.449 √ó 3 
     + 1.008 √ó 3 √ó 2.3 
     + 0.479 √ó 3 √ó 2.3 √ó 1.7

     = 1.000 + 4.347 + 6.955 + 5.606
     = 17.908
```

**Verification**: The actual value is e¬≥ ‚âà 20.086. Our estimate 17.908 is reasonable given we're extrapolating! 

#### Connection to Other Forms

**Relation to Lagrange Interpolation**:
- Newton and Lagrange produce the **same polynomial**
- Newton:  Builds incrementally, easy to add points
- Lagrange: Direct formula, harder to add points

**Relation to Forward/Backward Differences**:
When spacing is equal (h = constant):
```
f[x·µ¢, x·µ¢‚Çä‚ÇÅ] = Œîy·µ¢ / h
f[x·µ¢, x·µ¢‚Çä‚ÇÅ, x·µ¢‚Çä‚ÇÇ] = Œî¬≤y·µ¢ / (2! h¬≤)
f[x‚ÇÄ,... ,x‚Çñ] = Œî·µèy‚ÇÄ / (k!h·µè)
```

So forward/backward interpolation are **special cases** of divided differences! 

#### Key Advantages Over Forward/Backward

**1. Flexibility in Data**:
```
Forward/Backward:   Must have x‚ÇÄ, x‚ÇÄ+h, x‚ÇÄ+2h, ...  (rigid)
Divided Difference: Any x‚ÇÄ, x‚ÇÅ, x‚ÇÇ, ... (flexible) ‚úì
```

**2. Incremental Updates**:
Adding a new point (x‚Çô‚Çä‚ÇÅ, y‚Çô‚Çä‚ÇÅ):
- Forward/Backward: Must rebuild entire table if spacing changes
- Divided Difference:  Just add one more column ‚úì

**3. Real-World Data**:
Most real data doesn't have perfect equal spacing!

### When to Use Divided Differences

**Optimal Scenarios**:  
‚úÖ **Non-uniformly spaced data** (most common case)  
‚úÖ **Experimental data** with irregular sampling  
‚úÖ **General-purpose interpolation** - works everywhere  
‚úÖ **Adding points incrementally** - table extends easily  
‚úÖ **Adaptive algorithms** - can choose optimal points  
‚úÖ **Legacy data** with missing or irregular entries  

**Real-World Examples**:
- Temperature readings at irregular times
- Stock prices (markets closed on weekends/holidays)
- Scientific measurements at varying intervals
- Historical data with gaps

**Still Use Forward/Backward When**:  
‚ùå Data is perfectly equally spaced (forward/backward slightly simpler)  
‚ùå Pedagogical purposes (easier to understand differences)  
‚ùå Historical compatibility (old tables in those formats)  

### Complexity Analysis

**Time Complexity**: 

1. **Building Table**:
   ```
   For j = 1 to n-1:      // n-1 iterations
       For i = 0 to n-j-1: // decreasing iterations
           // O(1) operation
   Total:  Œ£‚±º‚Çå‚ÇÅ‚Åø‚Åª¬π(n-j) = n(n-1)/2
   ```
   **Complexity**:  O(n¬≤)

2. **Single Interpolation**:
   - Direct method: O(n) operations
   - Horner's method: O(n) operations (slightly fewer multiplications)

3. **k Interpolations**:  O(n¬≤ + kn)

**Space Complexity**:
- Full table: O(n¬≤)
- Optimized (only top row needed): O(n)

**Operation Counts** (single interpolation, n points):
- **Divisions**: ~n¬≤/2 (building table)
- **Multiplications**: ~n¬≤/2 (table) + ~n (evaluation)
- **Additions/Subtractions**: ~n¬≤/2 (table) + ~n (evaluation)

### Numerical Considerations

**Error Sources**: 

1. **Subtraction in Numerator**:
   - When f[x·µ¢‚Çä‚ÇÅ,‚±º‚Çã‚ÇÅ] ‚âà f[x·µ¢,‚±º‚Çã‚ÇÅ], subtractive cancellation occurs
   - Loss of significant digits
   - **Mitigation**: Use higher precision

2. **Small Denominators**:
   - When x·µ¢‚Çä‚±º - x·µ¢ is small (nearly duplicate points)
   - Amplifies numerator errors
   - **Mitigation**:  Remove near-duplicate points, validate spacing

3. **Condition Number**:
   - Poorly spaced points increase condition number
   - **Best**:  Chebyshev points (cosine distribution)
   - **Worst**: Equally spaced endpoints (Runge's phenomenon)

**Stability Tips**:  
‚úÖ Check for duplicate x-values before building table  
‚úÖ Use double precision (at least)  
‚úÖ Avoid extreme non-uniformity in spacing  
‚úÖ Monitor high-order divided differences (should decrease)  
‚úÖ Consider Chebyshev points for better conditioning  

### Error Analysis

**Interpolation Error Formula**:
```
E(x) = f(x) - P‚Çô(x) = f[x‚ÇÄ,x‚ÇÅ,...,x‚Çô,x] √ó ‚àè·µ¢‚Çå‚ÇÄ‚Åø(x - x·µ¢)
```

Where f[x‚ÇÄ,... ,x‚Çô,x] is the (n+1)th divided difference.

**Practical Error Bound**:
If |f‚ÅΩ‚Åø‚Å∫¬π‚Åæ(Œæ)| ‚â§ M for some Œæ in [min x·µ¢, max x·µ¢]: 
```
|E(x)| ‚â§ (M / (n+1)!) √ó |‚àè·µ¢‚Çå‚ÇÄ‚Åø(x - x·µ¢)|
```

**Implications**:
- Error depends on smoothness of f (via f‚ÅΩ‚Åø‚Å∫¬π‚Åæ)
- Product term is zero at data points (exact interpolation)
- Error smallest near cluster of data points
- Error largest in gaps between data points

### Advantages & Limitations

**Advantages**:  
‚úÖ **Most general** Newton method - no spacing restrictions  
‚úÖ **Real-world ready** - works with actual data  
‚úÖ **Incremental updates** - easy to add new points  
‚úÖ **Flexible** - handles any distinct x-values  
‚úÖ **Same polynomial** as Lagrange but easier to compute  
‚úÖ **Error estimation** - from high-order terms  
‚úÖ **Industry standard** - most numerical libraries use this  
‚úÖ **Numerically stable** with proper implementation  

**Limitations**:  
‚ùå **More complex** than forward/backward (but not much)  
‚ùå **Duplicate detection needed** - must validate input  
‚ùå **Slightly more operations** than specialized equal-spacing methods  
‚ùå **Runge's phenomenon** still possible with many points  
‚ùå **Not optimal for derivatives** - finite differences better for that  

**Bottom Line**:  This is the **go-to method** for general interpolation! 

---

## üìä Method Comparison

### Comprehensive Comparison Table

| Aspect | Forward | Backward | Divided Difference |
|--------|---------|----------|-------------------|
| **Spacing Requirement** | Equal (strict) | Equal (strict) | Any (flexible) ‚úì |
| **Reference Point** | First (x‚ÇÄ) | Last (x‚Çô) | All points |
| **Best Accuracy Region** | Near start | Near end | Everywhere |
| **Difference Operator** | Œî (forward) | ‚àá (backward) | Divided (/) |
| **Table Structure** | Top row | Bottom row | Top row |
| **Table Complexity** | O(n¬≤) | O(n¬≤) | O(n¬≤) |
| **Interpolation Complexity** | O(n) | O(n) | O(n) |
| **Memory** | O(n¬≤) | O(n¬≤) | O(n¬≤) |
| **Incremental Updates** | Hard | Hard | Easy ‚úì |
| **General Purpose** | No | No | Yes ‚úì |
| **Historical Usage** | Math tables | Navigation | Modern computing |
| **Implementation** | Simple | Simple | Moderate |

### When to Use Each Method? 

**Decision Tree**: 

```
Are data points equally spaced?
‚îú‚îÄ YES ‚Üí Where do you need to interpolate?
‚îÇ        ‚îú‚îÄ Near beginning ‚Üí Newton's Forward
‚îÇ        ‚îú‚îÄ Near end ‚Üí Newton's Backward
‚îÇ        ‚îî‚îÄ Throughout ‚Üí Any method works, divided difference most flexible
‚îÇ
‚îî‚îÄ NO ‚Üí Newton's Divided Difference (only option)
```

### Accuracy Comparison

For the same data and interpolation point, all three methods produce the **same polynomial** (when applicable). The difference is in: 

1. **Numerical stability**:  Divided difference can be slightly less stable with poor spacing
2. **Computation efficiency**: Forward/backward slightly faster with equal spacing
3. **Applicability**: Only divided difference works universally

**Example**: Interpolating sin(x) at x = 0.25 using 5 points

```
Method                    Result          Error        Speed
Forward (0 to 1)         0.247404        3.0e-6       Fast
Backward (0 to 1)        0.247404        3.0e-6       Fast
Divided Diff (0 to 1)    0.247404        3.0e-6       Fast
Divided Diff (irregular) 0.247398        9.2e-6       Fast
```

All are accurate, but divided difference handles both cases! 

### Computational Cost (n = 10 points)

| Operation | Forward | Backward | Divided Diff |
|-----------|---------|----------|--------------|
| Table Build | 45 ops | 45 ops | 45 ops |
| Interpolate (1x) | 10 ops | 10 ops | 10 ops |
| Add New Point | Rebuild (45) | Rebuild (45) | Add column (10) ‚úì |

---

## üéØ Applications

### Scientific and Engineering Applications

#### 1. **Experimental Data Analysis** üî¨

**Problem**: Laboratory measurements at irregular time intervals

**Scenario**:
- Chemical reaction sampled at t = 0, 0.5, 1.2, 2.1, 3.5, 5.0 minutes
- Need concentration at t = 1.5 minutes

**Method**: Newton's Divided Difference (irregular spacing)

**Why Interpolation?**:  More reliable than fitting a complex model when underlying physics is partially known. 

#### 2. **Signal Processing** üì°

**Problem**: Reconstruct continuous signal from discrete samples

**Applications**:
- Audio upsampling (increase sample rate)
- Image scaling (enlarge photos)
- Video frame interpolation (slow motion)

**Method**: Typically divided difference or specialized methods (cubic splines)

**Example**: Convert 44.1 kHz audio to 48 kHz for video synchronization. 

#### 3. **Weather Prediction** üå¶Ô∏è

**Problem**: Estimate temperature/pressure between weather stations

**Scenario**:
- Stations at irregular geographic positions
- Need values for grid-based numerical models

**Method**:  Divided difference for spatial interpolation

**Real Impact**: Improves accuracy of weather forecasting models! 

#### 4. **Engineering Tables** üìê

**Historical Application**: Before calculators and computers

**Example**: Steam tables
- Pressure, temperature, enthalpy at specific points
- Engineers interpolated for intermediate values

**Method**: Forward/backward (tables were equally spaced for this reason!)

**Modern Use**: Still used for quick estimates! 

### Computer Science Applications

#### 5. **Computer Graphics** üé®

**Curve Generation**:
- User clicks 5 points
- Computer draws smooth curve through them
- Interpolation creates intermediate points

**Animation**:
- Keyframe at t = 0, 1, 3, 5 seconds
- Interpolate positions at t = 0.1, 0.2, ... 
- Creates smooth motion

**Font Rendering**:
- Outline defined by control points
- Interpolation generates smooth curves
- TrueType fonts use polynomial curves

#### 6. **Game Development** üéÆ

**Camera Paths**:
- Define camera positions at key moments
- Interpolate smooth path between them
- Player experiences cinematic movement

**Particle Systems**:
- Particle properties (size, color, speed) over time
- Interpolate between keyframes
- Creates complex effects efficiently

#### 7. **Data Visualization** üìà

**Smooth Plotting**:
- Plot 10 data points
- Draw smooth curve through them
- Makes trends more visible

**Missing Data**:
- Sensor failed at some readings
- Interpolate to fill gaps
- Enables continuous analysis

### Financial Applications

#### 8. **Option Pricing** üíπ

**Problem**: Option price depends on volatility surface

**Data**: Known prices at specific strikes/maturities
**Need**: Price for arbitrary strike/maturity
**Method**: 2D interpolation (combination of 1D interpolations)

**Impact**: Billions of dollars in daily trading rely on accurate interpolation!

#### 9. **Yield Curve Construction** üìä

**Problem**: Interest rates known at specific maturities

**Example**:
- 1-month:  2.5%
- 3-month: 2.7%
- 6-month:  2.9%
- 1-year:  3.2%

**Need**: Rate for 4-month loan

**Method**: Divided difference interpolation

**Use**:  Pricing bonds, derivatives, risk management

### Medical Applications

#### 10. **Medical Imaging** üè•

**CT/MRI Scans**:
- Slices captured at specific intervals (e.g., every 5mm)
- Interpolate to estimate tissue density between slices
- Enables 3D reconstruction

**Radiation Treatment**:
- Plan radiation dose at specific points
- Interpolate to ensure proper dose distribution
- Critical for targeting tumors while sparing healthy tissue

**Prosthetic Design**:
- Measure body contours at specific locations
- Interpolate to create smooth 3D model
- Enables custom-fitted prosthetics

### Aerospace Applications

#### 11. **Trajectory Planning** üöÄ

**Problem**: Spacecraft position at specific times

**Given**: Position at t = 0, 100, 200, 300 seconds
**Need**: Position at t = 150 seconds for mid-course correction

**Method**:  Divided difference (time intervals may vary)

**Impact**: Essential for navigation and rendezvous operations

#### 12. **Aerodynamic Tables** ‚úàÔ∏è

**Problem**: Lift/drag coefficients measured at specific angles

**Data**: Wind tunnel tests at Œ± = 0¬∞, 5¬∞, 10¬∞, 15¬∞, 20¬∞
**Need**:  Coefficient at Œ± = 12¬∞ for flight simulation

**Method**: Newton interpolation

**Use**: Aircraft design, flight simulators, autopilot systems

### Environmental Science

#### 13. **Climate Modeling** üåç

**Temperature Reconstruction**:
- Historical data at irregular intervals
- Ice core samples, tree rings (non-uniform time spacing)
- Interpolate to create continuous temperature record

**Pollution Mapping**:
- Sensors at scattered locations
- Interpolate to estimate pollution levels city-wide
- Informs public health decisions

---

## üìÅ Implementation Structure

Each method folder contains: 

```
Method Name/
‚îú‚îÄ‚îÄ README.md                              # Detailed theory and examples
‚îú‚îÄ‚îÄ newtons-[method]-interpolation.cpp    # C++ implementation
‚îú‚îÄ‚îÄ input1.txt                            # Basic test case
‚îú‚îÄ‚îÄ input2.txt                            # Error analysis case
‚îú‚îÄ‚îÄ output1.txt                           # Expected output 1
‚îú‚îÄ‚îÄ output2.txt                           # Expected output 2
```

### Common Features Across All Implementations

**Input/Output**:
- ‚úÖ File-based I/O for batch processing
- ‚úÖ Multiple test cases per file
- ‚úÖ Formatted output with configurable precision
- ‚úÖ Dual output (console and file)

**Visualization**:
- ‚úÖ Data points table display
- ‚úÖ Complete difference/divided difference table
- ‚úÖ Step-by-step interpolation results
- ‚úÖ Optional error analysis with additional points

**Error Handling**:
- ‚úÖ Equal spacing validation (forward/backward)
- ‚úÖ Duplicate x-value detection (divided difference)
- ‚úÖ Extrapolation warnings
- ‚úÖ Input validation and meaningful error messages

**Code Quality**:
- ‚úÖ Well-commented code
- ‚úÖ Consistent formatting
- ‚úÖ Readable variable names
- ‚úÖ Modular structure with utility functions

---

## üöÄ Getting Started

### Prerequisites
- **C++ Compiler**: g++, clang++, or MSVC
- **C++ Standard**: C++11 or later
- **Text Editor/IDE**: VS Code, CLion, or any preferred editor
- **Basic Knowledge**: Understanding of polynomials and basic calculus

### Compilation

Navigate to any method folder and compile:

```bash
# Standard compilation
g++ -o interpolate newtons-[method]-interpolation. cpp -std=c++11

# With optimization (recommended)
g++ -o interpolate newtons-[method]-interpolation. cpp -std=c++17 -O2

# With warnings (for development)
g++ -o interpolate newtons-[method]-interpolation.cpp -std=c++17 -O2 -Wall -Wextra
```

### Execution

```bash
# Run the compiled program
./interpolate

# On Windows
interpolate.exe
```

The program: 
1. Reads input from `input1.txt` or `input2.txt`
2. Processes all interpolation requests
3. Writes results to corresponding output file
4. Displays results on console

### Input Format

**Basic Format** (input1.txt):
```
n                           # Number of data points
x‚ÇÄ y‚ÇÄ                      # First data point
x‚ÇÅ y‚ÇÅ                      # Second data point
...
x‚Çô‚Çã‚ÇÅ y‚Çô‚Çã‚ÇÅ                  # Last data point
m                           # Number of interpolation points
x_interp‚ÇÅ                   # First interpolation point
x_interp‚ÇÇ                   # Second interpolation point
...
x_interp‚Çò                   # Last interpolation point
```

**With Error Analysis** (input2.txt):
```
n                           # Number of initial data points
x‚ÇÄ y‚ÇÄ
x‚ÇÅ y‚ÇÅ
...
x‚Çô‚Çã‚ÇÅ y‚Çô‚Çã‚ÇÅ
m                           # Number of interpolation points
x_interp‚ÇÅ
... 
x_interp‚Çò
x‚Çô y‚Çô                      # Additional point for error comparison
```

**Example** (Forward/Backward Interpolation):
```
5
0.0 1.0
0.5 1.6487
1.0 2.7183
1.5 4.4817
2.0 7.3891
3
1.25
1.75
1.85
```

**Example** (Divided Difference with irregular spacing):
```
5
0.0 1.0
0.7 2.014
1.3 3.669
2.0 7.389
2.8 16.445
3
0.5
1.5
2.5
```

### Output Format

Each run produces:
1. **Header** with method name
2. **Data points table** showing input data
3. **Difference table** (forward/backward/divided)
4. **Interpolation results** for each requested point
5. **Optional error analysis** if additional point provided

### Customization Options

**Toggle Intermediate Output**:
```cpp
bool printIntermediate = true;  // Set to false for final results only
```

**Adjust Precision**:
```cpp
fout << fixed << setprecision(6);  // Change 6 to desired decimal places
```

**Modify Tolerance**:
```cpp
const double EPSILON = 1e-12;  // Adjust for your numerical requirements
```

---

## üìö References

- **Numerical Methods for Engineers** by Chapra & Canale
- [Wikipedia: Polynomial Interpolation](https://en.wikipedia.org/wiki/Polynomial_interpolation)

---

## üë®‚Äçüíª Author

**Abir Hasan Arko**  
Roll: 2207053   
CSE, KUET    
[![GitHub](https://img.shields.io/badge/GitHub-AbirHasanArko-181717?style=flat&logo=github)](https://github.com/AbirHasanArko)

---

<div align="center">

**[‚¨Ü Back to Top](#interpolation-and-approximation)**

Part of the [Numerical Computing Suite](https://github.com/AbirHasanArko/Numerical-Computing-Suite)

</div>